{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqhklyZ_zeFa"
      },
      "source": [
        "# PyTorch for Beginners\n",
        "\n",
        "In this notebook, we will try out the codes we used in the [PyTorch for Beginners](https://www.learnopencv.com/pytorch-for-beginners-basics/) blog.\n",
        "\n",
        "\n",
        " <img src='https://opencv.org/wp-content/uploads/2023/05/c3_w1_pytorch_basics_cover.jpg' width=700 align='center'><br/>\n",
        "\n",
        "Let's start off by installing PyTorch.\n",
        "\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "* [1. Converting Image to tensors](#1.-Converting-Image-to-tensors)\n",
        "* [2. Introduction to Tensors and its Operations](#2.-Introduction-to-Tensors-and-its-Operations)\n",
        "\n",
        "* [3. Conclusion](#5.-Conclusion)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "TfSSU72-wLrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lu6Nap-AzvIk"
      },
      "outputs": [],
      "source": [
        "# Use this if you have conda installed\n",
        "# !conda install -c pytorch pytorch\n",
        "\n",
        "# Use this if you are on Google Colab\n",
        "# or don't have conda installed\n",
        "# !pip3 install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some digit images from MNIST dataset\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\" -O \"mnist_0.jpg\"\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\" -O \"mnist_1.jpg\""
      ],
      "metadata": {
        "id": "-PfSnTVfcwMO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXlDsyiT0QkG"
      },
      "source": [
        "Let's verify that we have the latest PyTorch version (1.1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XTu5IogH3Xgq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peb4GAdVnVI",
        "outputId": "e605d49b-baf2-45aa-b01f-181424cc9620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version : 2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "print(\"torch version : {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Converting Images to Batched tensors\n",
        "\n",
        "An image is made up of pixel arrays that represent the intensity of pixels in grayscale or the color values in RGB format. When working with deep learning models, it's often necessary to convert these images into tensors, which are the primary data structures used in PyTorch for handling and processing data.\n",
        "\n",
        "* **Tensors**: In PyTorch, tensors are multi-dimensional arrays similar to NumPy arrays, but with additional capabilities for GPU acceleration and automatic differentiation. Tensors are the fundamental building blocks for representing data and parameters in neural networks.\n",
        "* **Batches**: Batching is a technique where multiple data samples (images, in this case) are grouped together into a single tensor. This allows efficient processing of multiple samples simultaneously, to take advantage of the parallel processing capabilities of modern hardware.\n"
      ],
      "metadata": {
        "id": "Lgbl_exQeSBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block, we will see an example of converting two MNIST images into a single batched tensor of shape `[2,3,28,28]`"
      ],
      "metadata": {
        "id": "Z12KLdsrp8xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit_0_array_og = cv2.imread(\"mnist_0.jpg\")\n",
        "digit_1_array_og = cv2.imread(\"mnist_1.jpg\")\n",
        "\n",
        "digit_0_array_gray = cv2.imread(\"mnist_0.jpg\",cv2.IMREAD_GRAYSCALE )\n",
        "digit_1_array_gray = cv2.imread(\"mnist_1.jpg\",cv2.IMREAD_GRAYSCALE )\n",
        "\n",
        "# Visualize the image\n",
        "\n",
        "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
        "\n",
        "\n",
        "axs[0].imshow(digit_0_array_og, cmap='gray',interpolation='none')\n",
        "axs[0].set_title(\"Digit 0 Image\")\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(digit_1_array_og, cmap=\"gray\", interpolation = 'none')\n",
        "axs[1].set_title(\"Digit 1 Image\")\n",
        "axs[1].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "kVI3AFLLbS3E",
        "outputId": "06bf9fd4-c335-45f1-de80-1c296151d52d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy array with three channels\n",
        "print(\"Image array shape: \",digit_0_array_og.shape)\n",
        "print(f\"Min pixel value:{np.min(digit_0_array_og)} ; Max pixel value : {np.max(digit_0_array_og)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttB6pUHUdIm4",
        "outputId": "e3f34b75-7514-4c77-cf31-debfb19de21a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image array shape:  (28, 28, 3)\n",
            "Min pixel value:0 ; Max pixel value : 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will have a look at 28x28 single channel image's pixel values\n",
        "digit_0_array_gray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "oUCmiJ7_nwtw",
        "outputId": "3d7456cc-c764-4574-c708-d1d9095396b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
              "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
              "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
              "          0,   0],\n",
              "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
              "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
              "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
              "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
              "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
              "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
              "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
              "          1,   5],\n",
              "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
              "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
              "          0,   4],\n",
              "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
              "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
              "          0,   3],\n",
              "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
              "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
              "          0,   2],\n",
              "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
              "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
              "          0,   2],\n",
              "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
              "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
              "          0,   3],\n",
              "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
              "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
              "          0,   5],\n",
              "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
              "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
              "          0,   6],\n",
              "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
              "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
              "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
              "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
              "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
              "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
              "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
              "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
              "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-0cb0a1f7-f9f8-410b-8373-9e367d8d55b5\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB5ElEQVR4nMWSv2sUURSFv3fnvXnzdrM7cQOSZFHWWhIRywgRKxG0sbEQJGCRP8BGC7WwsQ+aXggsgpWInWJhUGsRURQSJIH8Yo3ZmezOzrXYjfgfeNvD+biccwDwhogGEUQQEKoYAPAeAEmwQGyRSKAKgEFiGwIIkUmRccTD8aFxDBIDCEAd8IEhC4DIgR2nUo9P3H2punxxGtKR5h1hDCxnX6luqm501y+AHT6SQgy1eKmj+fbbJ28Gxe+NOy4eOcFz7vWPMsuXThJP0rq9pSsjrIUKD7uarV4BAQ/nd9dmBeMAS33uo+r7GZOCwQo86rY9WISAvV8U71qAI7Jg3FX9Pm6IcCTwuMxmPUnARhFYJvJyyiK2b3oY8rAuFAUuA4RmbJwBgRJ30C+ms1QIJcBg4rLpGDAiivR7yYdPzU6vkR0meDPYOdVNyxIRC6Ih/mx+WnZjcgqtzNyo9Ac6qs0t781Tx2ISArht1eVhCKGKuadzGBxGgGZbsy/To4iEqYX8mifGAO7MM93XpSOpArWvmlIlxPiFvcN9fTo7FFOQmFub3ZXFydalBy8OMtXn9m/ZSYTMr5W5dlVVVXeu12ocO+ICNFa3eqqqv7R9unG0L8RhjUsIi+1Ortm3m5V/FvQf7g9SnKBxm+913QAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
              "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
              "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
              "          0,   0],\n",
              "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
              "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
              "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
              "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
              "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
              "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
              "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
              "          1,   5],\n",
              "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
              "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
              "          0,   4],\n",
              "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
              "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
              "          0,   3],\n",
              "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
              "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
              "          0,   2],\n",
              "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
              "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
              "          0,   2],\n",
              "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
              "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
              "          0,   3],\n",
              "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
              "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
              "          0,   5],\n",
              "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
              "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
              "          0,   6],\n",
              "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
              "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
              "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
              "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
              "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
              "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
              "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
              "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
              "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-0cb0a1f7-f9f8-410b-8373-9e367d8d55b5 button').onclick = (e) => {\n",
              "        document.querySelector('#id-0cb0a1f7-f9f8-410b-8373-9e367d8d55b5').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-0cb0a1f7-f9f8-410b-8373-9e367d8d55b5 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Convert Numpy array to Torch tensors"
      ],
      "metadata": {
        "id": "hKA82xa7xDW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the images to PyTorch tensors and normalize\n",
        "img_tensor_0 = torch.tensor(digit_0_array_og, dtype=torch.float32) / 255.0\n",
        "img_tensor_1 = torch.tensor(digit_1_array_og, dtype=torch.float32) / 255.0\n",
        "\n",
        "print(\"Shape of Normalised Digit 0 Tensor: \", img_tensor_0.shape)\n",
        "print(f\"Normalised Min pixel value: {torch.min(img_tensor_0)} ; Normalised Max pixel value : {torch.max(img_tensor_0)}\")\n",
        "\n",
        "plt.imshow(img_tensor_0,cmap=\"gray\")\n",
        "plt.title(\"Normalised Digit 0 Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "X3XeGklJdz36",
        "outputId": "64ee0c50-8f56-4e23-d0f0-60f4eda2b262"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Normalised Digit 0 Tensor:  torch.Size([28, 28, 3])\n",
            "Normalised Min pixel value: 0.0 ; Normalised Max pixel value : 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Creating Input Batch"
      ],
      "metadata": {
        "id": "K6C1MPtrgRYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_tensor = torch.stack([img_tensor_0, img_tensor_1])\n",
        "\n",
        "# In PyTorch the forward pass of input images to the model is expected to have a batch_size > 1\n",
        "print(\"Batch Tensor Shape:\", batch_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSLTIn0QgVC4",
        "outputId": "a4e3998a-2ae4-483a-9173-3c48400aa19e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Tensor Shape: torch.Size([2, 28, 28, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally in PyTorch, image tensors typically follow the shape convention **[N\n",
        ",C ,H ,W]** unlike tensorflow which follows [N, H, W, C].\n",
        "\n",
        "Therefore, we need to bring the color channel to the second dimension. This can be achieved using either `torch.view()` or `torch.permute()`.\n"
      ],
      "metadata": {
        "id": "Fp_qlCZGhHSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input = batch_tensor.permute(0,3,1,2)\n",
        "print(\"Batch Tensor Shape:\", batch_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv3D1A0fhlIR",
        "outputId": "13f4adeb-544f-4d34-b017-0da7aa3a9d08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Tensor Shape: torch.Size([2, 3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp--FrJM0eoO"
      },
      "source": [
        "# 2. Introduction to Tensors and its Operations\n",
        "\n",
        "We have seen the importance of tensors, now will understand it from ground up.\n",
        "Tensor is simply a fancy name given to matrices. If you are familiar with NumPy arrays, understanding and using PyTorch Tensors will be very easy. A scalar value is represented by a 0-dimensional Tensor. Similarly, a column/row matrix is represented using a 1-D Tensor and so on. Some examples of Tensors with different dimensions are shown for you to visualize and understand.\n",
        "\n",
        "<img src=https://learnopencv.com/wp-content/uploads/2019/05/PyTorch-Tensors.jpg width = 400 height=350>\n",
        "\n",
        "## 2.1. Construct your first Tensor\n",
        "\n",
        "Lets see how we can create a PyTorch Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwnMQMkHvbV_",
        "outputId": "d8ab0621-590d-488a-dcab-127410b36d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# Create a Tensor with just ones in a column\n",
        "a = torch.ones(5)\n",
        "# Print the tensor we created\n",
        "print(a)\n",
        "\n",
        "# Create a Tensor with just zeros in a column\n",
        "b = torch.zeros(5)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZRb8bDz02PZ"
      },
      "source": [
        "We can similarly create Tensor with custom values as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhuPnpNh0qMj",
        "outputId": "bf645e49-6b79-4099-8f24-2ff0d0c61781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ],
      "source": [
        "c = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj4kSyaR08-5"
      },
      "source": [
        "In all the above cases, we have created vectors or Tensors of dimension 1. Now, lets create some tensors of higher dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwLThRRw05BJ",
        "outputId": "b823df76-8221-4c10-83ec-b162ecfe5b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ],
      "source": [
        "d = torch.zeros(3,2)\n",
        "print(d)\n",
        "\n",
        "e = torch.ones(3,2)\n",
        "print(e)\n",
        "\n",
        "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
        "print(f)\n",
        "\n",
        "# 3D Tensor\n",
        "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cp28SfQ1Eb-"
      },
      "source": [
        "We can also find out the shape of a Tensor using **`.shape`** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrUhi7Me1CaE",
        "outputId": "cb7ac2c6-3315-4f74-adab-0c81f26443e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f.shape)\n",
        "\n",
        "print(e.shape)\n",
        "\n",
        "print(g.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWHot39h1Z0X"
      },
      "source": [
        "## 2.2. Access an element in Tensor\n",
        "\n",
        "Now that we have created some tensors, lets see how we can access an element in a Tensor. First lets see how to do this for 1D Tensor aka vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HP4gzrE1K66",
        "outputId": "2fa7db6a-f80e-4981-87b9-14e7bcd3f555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n"
          ]
        }
      ],
      "source": [
        "# Get element at index 2\n",
        "print(c[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gqFHFCV1k3H"
      },
      "source": [
        "What about 2D or 3D Tensor? Recall what we mentioned about **dimension of a tensor**.\n",
        "\n",
        "To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor. Thats why for tensor **`c`** we only had to specify one index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFR280DU1fJr",
        "outputId": "d2b6ea69-c9b5-4a38-a737-8c4a7bd5e73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n",
            "tensor(3.)\n",
            "tensor(5.)\n",
            "tensor(5.)\n"
          ]
        }
      ],
      "source": [
        "# All indices starting from 0\n",
        "\n",
        "# Get element at row 1, column 0\n",
        "print(f[1,0])\n",
        "\n",
        "# We can also use the following\n",
        "print(f[1][0])\n",
        "\n",
        "# Similarly for 3D Tensor\n",
        "print(g[1,0,0])\n",
        "print(g[1][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD0vwWDG1xr4"
      },
      "source": [
        "But what if you wanted to access one entire row in a 2D Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB_p7OUz1u9p",
        "outputId": "2d0ccbdc-1d81-4614-d94d-92c5dec12f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([2., 3.])\n",
            "tensor([1., 2., 3., 4.])\n",
            "tensor([1., 2.])\n",
            "tensor([2., 4.])\n"
          ]
        }
      ],
      "source": [
        "# All elements\n",
        "print(f[:])\n",
        "\n",
        "# All elements from index 1 to 2 (excluding element 3)\n",
        "print(c[1:3])\n",
        "\n",
        "# All elements till index 4 (exclusive)\n",
        "print(c[:4])\n",
        "\n",
        "# First row\n",
        "print(f[0, :])\n",
        "\n",
        "# Second column\n",
        "print(f[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxO2VoJv12Hh"
      },
      "source": [
        "## 2.3. Specify data type of elements\n",
        "\n",
        "Whenever we create a tensor, PyTorch decides the data type of the elements of the tensor such that the data type can cover all the elements of the tensor. We can override this by specifying the data type while creating the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AyDrCBS1z_x",
        "outputId": "04eaa176-b5d3-432f-b28d-7204dc46e250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.int64\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(int_tensor.dtype)\n",
        "\n",
        "# What if we changed any one element to floating point number?\n",
        "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
        "print(int_tensor.dtype)\n",
        "print(int_tensor)\n",
        "\n",
        "# This can be overridden as follows\n",
        "float_tensor = torch.tensor([[1, 2, 3],[4., 5, 6]])\n",
        "int_tensor = float_tensor.type(torch.int64)\n",
        "print(int_tensor.dtype)\n",
        "print(int_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwxIIWEF2Ea8"
      },
      "source": [
        "## 2.4. Tensor to/from NumPy Array\n",
        "\n",
        "We have mentioned several times that PyTorch Tensors and NumPy arrays are pretty similar. This of course demands the question if its possible to convert one data structure into another. Lets see how we can do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7AC_jpn2Cd6",
        "outputId": "5aa5cb0d-22b0-4fc4-e993-c3352f98f1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "tensor([[8, 7, 6, 5],\n",
            "        [4, 3, 2, 1]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor to Array\n",
        "f_numpy = f.numpy()\n",
        "print(f_numpy)\n",
        "\n",
        "# Array to Tensor\n",
        "h = np.array([[8,7,6,5],[4,3,2,1]])\n",
        "h_tensor = torch.from_numpy(h)\n",
        "print(h_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBlMxo7j2NNH"
      },
      "source": [
        "## 2.5. Arithmetic Operations on Tensors\n",
        "\n",
        "Now its time for the next step. Lets see how we can perform arithmetic operations on PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJGjZc212K74",
        "outputId": "3fe558f6-f711-49d6-d705-292dddcefa6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  4,  0],\n",
            "        [ 8,  0, 12]])\n",
            "tensor([[ 0,  4,  0],\n",
            "        [ 8,  0, 12]])\n",
            "tensor([[ 2,  0,  6],\n",
            "        [ 0, 10,  0]])\n",
            "tensor([[ 2,  0,  6],\n",
            "        [ 0, 10,  0]])\n",
            "tensor([[ 2,  4,  6],\n",
            "        [ 8, 10, 12]])\n",
            "tensor([[ -1,   4,  -9],\n",
            "        [ 16, -25,  36]])\n",
            "tensor([[22, 28],\n",
            "        [49, 64]])\n",
            "tensor([[0.5000, 1.0000, 1.5000],\n",
            "        [2.0000, 2.5000, 3.0000]])\n",
            "tensor([[-1.,  1., -1.],\n",
            "        [ 1., -1.,  1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor\n",
        "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
        "tensor2 = torch.tensor([[-1,2,-3],[4,-5,6]])\n",
        "\n",
        "# Addition\n",
        "print(tensor1+tensor2)\n",
        "# We can also use\n",
        "print(torch.add(tensor1,tensor2))\n",
        "\n",
        "# Subtraction\n",
        "print(tensor1-tensor2)\n",
        "# We can also use\n",
        "print(torch.sub(tensor1,tensor2))\n",
        "\n",
        "# Multiplication\n",
        "# Tensor with Scalar\n",
        "print(tensor1 * 2)\n",
        "\n",
        "# Tensor with another tensor\n",
        "# Elementwise Multiplication\n",
        "print(tensor1 * tensor2)\n",
        "\n",
        "# Matrix multiplication\n",
        "tensor3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "print(torch.mm(tensor1,tensor3))\n",
        "\n",
        "# Division\n",
        "# Tensor with scalar\n",
        "print(tensor1/2)\n",
        "\n",
        "# Tensor with another tensor\n",
        "# Elementwise division\n",
        "print(tensor1/tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6. Broadcasting"
      ],
      "metadata": {
        "id": "n-wQZvbukBRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - `a` is a 1-dimensional tensor with shape \\([ 3 ]\\).\n",
        "   - `b` is a scalar tensor with shape \\([ 1 ]\\).\n",
        "   - When adding `a` and `b`, PyTorch broadcasts `b` to match the shape of `a`, resulting in \\([ 1 + 4, 2 + 4, 3 + 4 ]\\).\n"
      ],
      "metadata": {
        "id": "LZ4u7hTLk1kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two 1-dimensional tensors\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4])\n",
        "\n",
        "# adding a scalar to a vector\n",
        "result = a + b\n",
        "\n",
        "print(\"Result of Broadcasting:\\n\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAPDFc7kkD7f",
        "outputId": "8ea51152-a637-4810-985e-68fcad1b7073"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of Broadcasting:\n",
            " tensor([5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) allows PyTorch to perform element-wise operations on tensors of\n",
        "   - `a` is a 2-dimensional tensor with shape \\([1, 3]\\).\n",
        "   - `b` is a 2-dimensional tensor with shape \\([3, 1]\\).\n",
        "   - When adding `a` and `b`, PyTorch broadcasts both tensors to the common shape \\([3, 3]\\), resulting in:\n",
        "   \n",
        "     \\\n",
        "     \\begin{bmatrix}\n",
        "     1+4 & 2+4 & 3+4 \\\\\n",
        "     1+5 & 2+5 & 3+5 \\\\\n",
        "     1+6 & 2+6 & 3+6 \\\\\n",
        "     \\end{bmatrix}\n",
        "     \\.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e88PB3fnk6p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two tensors with shapes (1, 3) and (3, 1)\n",
        "a = torch.tensor([[1, 2, 3]])\n",
        "b = torch.tensor([[4], [5], [6]])\n",
        "\n",
        "# adding tensors of different shapes\n",
        "result = a + b\n",
        "print(\"Shape: \", result.shape)\n",
        "print(\"\\n\")\n",
        "print(\"Result of Broadcasting:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOoy7pRMk6Kx",
        "outputId": "91c7d815-fcd5-4118-f818-62d8fac04a20"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  torch.Size([3, 3])\n",
            "\n",
            "\n",
            "Result of Broadcasting:\n",
            " tensor([[5, 6, 7],\n",
            "        [6, 7, 8],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkyA9q3_2mkE"
      },
      "source": [
        "## 2.7. CPU v/s GPU Tensor\n",
        "\n",
        "Lets first see how to create a tensor for GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-zGZj6qR2XhM"
      },
      "outputs": [],
      "source": [
        "# Create a tensor for CPU\n",
        "# This will occupy CPU RAM\n",
        "tensor_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')\n",
        "\n",
        "# Create a tensor for GPU\n",
        "# This will occupy GPU RAM\n",
        "tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEU85m327Oc"
      },
      "source": [
        "Just like tensor creation, the operations performed for CPU and GPU tensors are also different and consume RAM corresponding to the device specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "GCga1AY-2slu"
      },
      "outputs": [],
      "source": [
        "# This uses CPU RAM\n",
        "tensor_cpu = tensor_cpu * 5\n",
        "\n",
        "# This uses GPU RAM\n",
        "# Focus on GPU RAM Consumption\n",
        "tensor_gpu = tensor_gpu * 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcJPGIwG2_Gk"
      },
      "source": [
        "We can move the GPU tensor to CPU and vice versa as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JjyOE2dG285K"
      },
      "outputs": [],
      "source": [
        "# Move GPU tensor to CPU\n",
        "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
        "\n",
        "# Move CPU tensor to GPU\n",
        "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znQT1rkq3BHL"
      },
      "source": [
        "# 3. Conclusion\n",
        "\n",
        "\n",
        "In this notebook, we started with constructing simple tensors and manipulating them. Next notebook, we will understand the functionality of Torch Autograd and its role in automatic differentiation and gradient computation.\n",
        "In the upcoming notebooks, we will go deeper into backpropagation and various computer vision tasks such as Classification, Segmentation, Object Detection, and Instance Segmentation. Each notebook will provide a detailed explanation and hands-on examples to help you serve as starter notebooks to master the essential tasks in computer vision."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-xo5g-msrfK"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}